{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Please convert this Python file to an IPython/Jupyter notebook using the\n",
    "# Makefile:\n",
    "#\n",
    "#  cd path/to/crashathon/notebooks\n",
    "#  make\n",
    "#\n",
    "# A recent IPython with notebook support is required to run the Make task.\n",
    "#\n",
    "# The notebook will write the result to files named in the form:\n",
    "#\n",
    "#   crashes_<channel>.json\n",
    "#\n",
    "# Once configured as scheduled Spark jobs they can be downloaded from the\n",
    "# Spark job cluster:\n",
    "#\n",
    "#   https://analysis-output.telemetry.mozilla.org/<job-name>/data/crashes_<channel>.json\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crashathon -- a Firefox crash collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import ujson as json\n",
    "from moztelemetry import get_pings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Some configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#: Number of days to fetch crash pings for\n",
    "DAYS = 30\n",
    "\n",
    "#: Fraction of pings to fetch\n",
    "FRACTION = 1\n",
    "\n",
    "#: The build channels to fetch and store crash pings for\n",
    "CHANNELS = [\n",
    "    'nightly',\n",
    "    'aurora',\n",
    "    'beta',\n",
    "    'release',\n",
    "]\n",
    "\n",
    "#: The time is now\n",
    "NOW = datetime.datetime.now()\n",
    "\n",
    "\n",
    "def get_crash_pings(channel, start_date, end_date, fraction):\n",
    "    pings = get_pings(\n",
    "        sc,  # noqa\n",
    "        app='Firefox',\n",
    "        channel=channel,\n",
    "        submission_date=(start_date, end_date),\n",
    "        build_id=('20100101000000', '99999999999999'),\n",
    "        doc_type='crash',\n",
    "        fraction=fraction,\n",
    "    )\n",
    "    return pings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given build channel, start and end date and a fraction, gets\n",
    "crash data, does some filtering and transformations and writes\n",
    "an anonymized JSON file with the number of crashes and some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_crashes(channel, start_date, end_date, fraction):\n",
    "    # get the raw crash data first\n",
    "    crash_pings = get_crash_pings(\n",
    "        channel,\n",
    "        start_date=start_date.strftime(\"%Y%m%d\"),\n",
    "        end_date=end_date.strftime(\"%Y%m%d\"),\n",
    "        fraction=fraction,\n",
    "    )\n",
    "    # drop crash data that doesn't have client IDs\n",
    "    non_empty_pings = crash_pings.filter(\n",
    "        lambda ping: ping.get('clientId') is not None,\n",
    "    )\n",
    "    # group by the client ID so we can build a list of occurences per client ID\n",
    "    grouped_pings = non_empty_pings.groupBy(\n",
    "        lambda ping: ping.get('clientId')\n",
    "    )\n",
    "    # get a list of crash occurences\n",
    "    crash_numbers = grouped_pings.map(\n",
    "        lambda data: len(data[1]),\n",
    "    )\n",
    "    # order by number to be nice to the people reading the file\n",
    "    ordered_numbers = crash_numbers.sortBy(lambda count: -count)\n",
    "\n",
    "    # build the data to write to the json data\n",
    "    data = {\n",
    "        'channel': channel,\n",
    "        'count': ordered_numbers.count(),\n",
    "        'crashes': ordered_numbers.collect(),\n",
    "        'start_date': start_date.isoformat(),\n",
    "        'end_date': end_date.isoformat(),\n",
    "    }\n",
    "    # write the data\n",
    "    output_path = os.path.join('output', 'crashes_%s.json' % channel)\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Store the aggregated crashes to disk for all configured channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for channel in CHANNELS:\n",
    "    start_date = (NOW - datetime.timedelta(days=DAYS)).date()\n",
    "    end_date = NOW.date()\n",
    "    print 'getting crashes for channel', channel\n",
    "    print 'starting', start_date, 'ending', end_date\n",
    "    print 'for a fraction of ', FRACTION\n",
    "    store_crashes(\n",
    "        channel,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        fraction=FRACTION,\n",
    "    )"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
